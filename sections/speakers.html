<div class="row me-row content-ct" id="speakers">
      <h2 class="row-title">Keynote Speakers</h2>
      <div class="row" id="lionelrobert">
        <div class="col-md-4 feature">
          <img src="img/robert.png" class="keynote-img">
          <h3>Lionel P. Robert</h3>
          <p>University of Michigan</p>
          <ul class="speaker-social">
            <li><a href="https://sites.google.com/umich.edu/lionelrobert/"><span class="ti-world"></span></a></li>
          </ul>
        </div>
        <div class="col-md-8 feature">
          <h3>The Problematic Problems of Human Trust in Robots:<br>Is Trusting a Robot More like a Teammate or a Tool
            and should we really care?</h3>
          <p>As robotics advances and permeates various aspects of our social and work lives, the question of how humans
            we view and ultimately trust robots has become increasingly pertinent. Do humans view them as mere machines,
            automated tools designed to serve their needs or do they embrace a more empathetic approach, viewing and
            trusting them as actual teammates (i.e. humans)? On the one hand, proponents of robots as possible humans
            argue that computers are social actors (CASA) and that humans mindlessly interact with computers in much the
            same way they do humans. This view is often used to justify the employment of human-to-human theories and
            their corresponding measures to understand human-robot interactions. On the other hand, advocates of
            mechanization contend that humans do not view robots as humans but instead as automated tools. This view
            discourages using human-to-human theories and their corresponding measures to understand human-robot
            interactions. They advocate for more human-to-automation theories and measures of constructs like trust. In
            this thought-provoking presentation, I will explore the arguments supporting both perspectives and consider
            the potential consequences of each approach. Ultimately, this presentation aims to provide a balanced
            understanding of the complexities involved to encourage a nuanced dialogue on the subject. </p>
          <p></p>
        </div>
      </div>
      <div class="row" id="myrthetielman">
        <div class="col-md-4 feature">
          <img src="img/tielman.png" class="keynote-img">
          <h3>Myrthe L. Tielman</h3>
          <p>Delft University of Technology</p>
          <ul class="speaker-social">
            <li><a href="http://ii.tudelft.nl/~myrthe/"><span class="ti-world"></span></a></li>
          </ul>
        </div>
        <div class="col-md-8 feature">
          <h3>Let's talk about trust</h3>
          <p>Trust is a hot topic. It’s something very important to humans, it’s important to teams, and it’s important
            for AI. So many people are looking into trust, and as human-AI team researchers it seems something we should
            care a lot about. But what do we actually mean when we talk about trust? There’s a lot of different
            perspectives and definitions. Should we care about that, or try to come to an agreement? In this talk, I
            argue that meaning is more important than agreement when it comes to words. But meaning is crucial, as
            through looking at the different meanings of trust, we also might gain new perspectives on how to achieve
            it.</p>
        </div>
      </div>
    </div>